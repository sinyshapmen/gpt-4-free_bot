"""Main file üëç."""

from __future__ import annotations

import logging
from pathlib import Path
from typing import TYPE_CHECKING

import tomllib
from g4f.client import Client
from g4f.cookies import read_cookie_files, set_cookies_dir
from g4f.Provider import (
    Gemini,
    Liaobots,
    OpenaiChat,
)
from g4f.Provider.openai.har_file import NoValidHarFileError
from telebot import TeleBot
from telebot.apihelper import ApiTelegramException

if TYPE_CHECKING:
    from telebot.types import Message

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# TODO: remove global variables access in functions
context: dict[int, list[dict[str, str]]] = {}
commands = ["/start", "/ask", "/reset"]

with Path("config.toml").open("rb") as f:
    config = tomllib.load(f)
token = config["bot"]["token"]
model_name = config["gpt"].get("model", "gpt-4o")

# setup cookies
cookies_dir = Path(__file__).parent / "har_and_cookies"
set_cookies_dir(cookies_dir)
read_cookie_files(cookies_dir)

bot = TeleBot(token)
logger.info("bot polling")


@bot.message_handler(commands=["start"])
def start_message(message: Message) -> None:
    """Send a message with instructions to the user.

    When the user first interacts with the bot (e.g. by typing /start), this
    function is called. It simply sends a message to the user with
    instructions on how to use the bot.
    """
    bot.send_message(message.chat.id, "–í–æ–ø—Ä–æ—Å: /ask")


@bot.message_handler(commands=["ask"])
def ask_message(message: Message) -> None:
    """Start the conversation with the user.

    When the user sends the /ask command, this function is called. It prompts
    the user to enter a question or message, and then registers
    process_ask_command to be called when the user replies.
    """
    bot.send_message(message.chat.id, "–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ:")
    bot.register_next_step_handler(message, process_ask_command)


def send_chunks(chat_id: int, text: str) -> None:
    """Send a long message to a chat by dividing it into chunks.

    This function takes a chat ID and a long text string, splits the text
    into chunks of 4096 characters or less, and sends each chunk as a separate
    message to the specified chat. The messages are formatted using Markdown.

    Args:
        chat_id (int): The ID of the chat where the message should be sent.
        text (str): The long text string to be divided and sent in chunks.

    """
    chunk_size = 4096
    chunks = [text[i : i + chunk_size] for i in range(0, len(text), chunk_size)]
    for chunk in chunks:
        bot.send_message(chat_id, chunk, parse_mode="Markdown")


def process_ask_command(message: Message) -> None:
    """Process a user's message and send a response back to the user.

    This function takes a `Message` object from the user, sends a "typing" action
    to the chat, and then attempts to generate a response to the user using
    the `Client` class from the `g4f` library. The generated response is then
    split into chunks and sent back to the user as separate messages.

    If the user's message is the first message in the conversation, the
    response is generated by calling `client.chat.completions.create` with a
    single message in the `messages` parameter. If the user's message is not the
    first message in the conversation, the response is generated by calling
    `client.chat.completions.create` with a list of messages in the `messages`
    parameter. The first message in the list is the user's message, and the
    second message is the previous response from the bot.

    After generating the response, the function registers
    `process_user_response` as the next step handler for the user's message.
    This allows the bot to respond to the user's message and then wait for the
    user to respond again.

    Args:
        message (Message): The message from the user to be processed.

    """
    user_input = message.text
    user_id = message.from_user.id
    search = bot.send_message(message.chat.id, "–ò–¥–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—è...")
    logger.info("user %s asked: %s", user_id, user_input)

    action_timeout = 600
    while True:
        client = Client(provider=OpenaiChat, image_provider=Gemini)
        try:
            # check if the user's message is the first message
            if message.chat.id not in context:
                response = client.chat.completions.create(
                    model=model_name or "gpt-4o",
                    messages=[{"role": "user", "content": user_input}],
                )
                # Get the generated text from the response
                generated_text = response.choices[0].message.content
                bot.delete_message(message.chat.id, search.message_id)
                context[message.chat.id] = [
                    {"role": "user", "content": user_input},
                    {"role": "assistant", "content": generated_text},
                ]
                # Send the generated text as a single message
                send_chunks(message.chat.id, generated_text)
                bot.register_next_step_handler(message, process_user_response)
                return

            context[message.chat.id].append({"role": "user", "content": user_input})
            response = client.chat.completions.create(
                model=model_name or "gpt-4o",
                messages=context[message.chat.id],
            )

            bot.send_chat_action(message.chat.id, "typing", action_timeout)
            generated_text = response.choices[0].message.content
            bot.delete_message(message.chat.id, search.message_id)

            context[message.chat.id].append(
                {"role": "assistant", "content": generated_text},
            )
            send_chunks(message.chat.id, generated_text)
            bot.register_next_step_handler(message, process_user_response)
        except NoValidHarFileError:
            logger.exception(
                "No valid .har file\nFor more information, see: https://github.com/xtekky/gpt4free?tab=readme-ov-file#using-har-and-cookie-files",
            )
            return
        except ApiTelegramException:
            logger.exception("Got an error from the Telegram API!")
            return
        else:
            return

        # TODO: add more exception handling


def process_user_response(message: Message) -> None:
    """Process a user's message and send a response back to the user.

    This function takes a `Message` object from the user, sends a "typing" action
    to the chat, and then attempts to generate a response to the user using
    the `Client` class from the `g4f` library. The generated response is then
    split into chunks and sent back to the user as separate messages.

    The response is generated by calling `client.chat.completions.create` with a
    list of messages in the `messages` parameter. The first message in the list
    is the user's message, and the second message is the previous response from
    the bot.

    After generating the response, the function registers itself as the next
    step handler for the user's message. This allows the bot to respond to the
    user's message and then wait for the user to respond again.

    Args:
        message (Message): The message from the user to be processed.

    """
    user_input = message.text
    search = bot.send_message(message.chat.id, "–ò–¥–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—è...")

    action_timeout = 600
    while True:
        client = Client(provider=Liaobots, image_provider=Gemini)
        try:
            context[message.chat.id].append({"role": "user", "content": user_input})
            response = client.chat.completions.create(
                model=model_name or "gpt-4o",
                messages=context[message.chat.id],
            )
            bot.send_chat_action(message.chat.id, "typing", action_timeout)
            generated_text = response.choices[0].message.content
            bot.delete_message(message.chat.id, search.message_id)
            send_chunks(message.chat.id, generated_text)
            context[message.chat.id].append(
                {"role": "assistant", "content": generated_text},
            )
            bot.register_next_step_handler(message, process_user_response)
        except ApiTelegramException:
            logger.exception("Got an error from the Telegram API!")
            continue


if __name__ == "__main__":
    bot.polling()
